{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732eb44c",
   "metadata": {},
   "source": [
    "# Text Analytics Final Project\n",
    "## Northwestern University\n",
    "## Spring 2025\n",
    "\n",
    "For your final project in Text Analytics, you will be working in groups of 4-5 to dissect a dataset, build a model that predicts something within that dataset, and create an interactive tool to display your results. You will also create a 10 minute presentation displaying your findings, your interactive tool, and anything else to accompany your project. This presentation should be recorded before the start of Week 10. These presentations will be collected together and shown for class on Week 10.\n",
    "\n",
    "You will have the option to choose **one** of the following datasets for your project. The options will have unique and shared tasks that must be completed, any you may create additional components as you see fit. Each option has easier and more difficult parts to it, as labeled below.\n",
    "\n",
    "**Please write to Evan by the end of class on Week 6:**\n",
    "* The members of your group\n",
    "* Which task you will be working on\n",
    "\n",
    "If you cannot find a group to work with you, please let Evan know ASAP.\n",
    "\n",
    "**Your final submission will be three things:**\n",
    "* A Github repo with your code and results, with instructions on how to run the code\n",
    "* A powerpoint presentation detailing your project and findings\n",
    "* A video presenting your presentation and code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5829785",
   "metadata": {},
   "source": [
    "## Option 1: Visual and Genre Classification\n",
    "\n",
    "* Data Processing: Easy\n",
    "* Modeling: Hard\n",
    "* Interactive: Medium\n",
    "\n",
    "This dataset is a unique collection of high-quality movie and series poster images from [IMDB](https://www.imdb.com/), meticulously handpicked to represent their respective genres accurately. Accompanying these images are detailed plot summaries, each containing more than 150 words, providing rich textual data for analysis. \n",
    "\n",
    "The dataset focuses on four primary genres: Action, Comedy, Horror, and Romance. The combination of visual and textual data makes this dataset ideal for multimodal analysis and genre classification tasks. It offers an excellent opportunity for researchers and enthusiasts to delve into the world of movies and series, explore genre characteristics, and develop models that can understand and predict genre based on visual cues and plot descriptions. This dataset is a valuable resource for anyone interested in film studies, machine learning, and data science.\n",
    "\n",
    "You are tasked to do the following:\n",
    "\n",
    "\n",
    "* Load in the data and analyze each column.\n",
    "* Clean the movie summary column in any way you see fit.\n",
    "* Build a summarization tool and summarize a few of the movies.\n",
    "* Build at least **four** models on the dataset. You must have at least one naive bayes model, one generalized linear model (ex: logistic regression), and one tensorflow model (ex: LSTM). \n",
    "* Evaulate the models in terms of overall accuracy and accuracy by genre.\n",
    "* For your tensorflow model(s), plot your models and plot accuracy over epoch number.\n",
    "* Show the most important words from each model and build a word cloud accompanying it. \n",
    "* Find movies that had a different prediction based on the model. Explain why you think those models predicted one genre vs. the other.\n",
    "* Build an interactive tool that can take a real or fake movie summary, clean the text, and predict the movie genre based on your models.\n",
    "* Add any other techniques taught from the course that could be applied for this project.\n",
    "* Present these findings in a 10 minute video with slides, sample code and a demonstration of your interactive tool.\n",
    "* BONUS (optional): extract the images and map them with the genre of movie. Build a model classifying the genre based on the movie images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbad1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"zulkarnainsaurav/imdb-multimodal-vision-and-nlp-genre-classification\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52106240",
   "metadata": {},
   "source": [
    "## Option 2: Summarization of Civil Rights Lawsuits\n",
    "\n",
    "* Data Processing: Medium\n",
    "* Modeling: Medium\n",
    "* Interactive: Medium\n",
    "\n",
    "The Multi-LexSum dataset is a collection of 9,280 legal case summaries, primarily in civil rights. Multi-LexSum is distinct from other datasets in its multiple target summaries, each at a different granularity (ranging from one-sentence “extreme” summaries to multi-paragraph narrations of over five hundred words). It presents a challenging multi-document summarization task given the long length of the source documents, often exceeding two hundred pages per case. Unlike other summarization datasets that are (semi-)automatically curated, Multi-LexSum consists of expert-authored summaries: the experts—lawyers and law students—are trained to follow carefully created guidelines, and their work is reviewed by an additional expert to ensure quality.\n",
    "\n",
    "You can find this data on huggingface [here](https://huggingface.co/datasets/allenai/multi_lexsum) and can download the code below. Note: the data are split into train/validation/test sets. You can use the train section for summarization and all three for modeling.\n",
    "\n",
    "\n",
    "You are tasked to do the following:\n",
    "\n",
    "* Load in the data and display any key findings.\n",
    "* Build a dataframe that collects the full case, summaries, and metadata (include the 'class_action_sought' and 'case_type' data as it will be used later).\n",
    "* Clean the cases. This will require removing parts of the text as well as the usual normalization process. \n",
    "* Provide summaries of each case the same way the dataset does:\n",
    "    - Long summary (multiple paragraphs)\n",
    "    - Short summary (one paragraph)\n",
    "    - Tiny summary (one sentence)\n",
    "* Analyze your findings. Do your summaries line up with the summaries given in the data?\n",
    "* Build a model with your cleaned case study as your feature and 'class_action_sought' as your output. Evaluate the model.\n",
    "* Build a model with your cleaned case study as your feature and 'case type' as your output. Evaluate the model. **Note**: there are many case types in the data. You may reduce the data to focus on only a few case types or group the case types into different categories. You must have more than 2 case types to model on.\n",
    "* Create an interactive tool that can take a real or fake legal case and have it spit out the following:\n",
    "    - Summaries of the study (long, short, and tiny)\n",
    "    - Prediction on whether there was a class action sought or not\n",
    "    - Prediction on the case type\n",
    "* Add any other techniques taught from the course that could be applied for this project.\n",
    "* Present these findings in a 10 minute video with slides, sample code and a demonstration of your interactive tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d435b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# multi_lexsum = load_dataset(\"allenai/multi_lexsum\", name=\"v20230518\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a10f5",
   "metadata": {},
   "source": [
    "## Option 3: Speech-to-Text Analysis\n",
    "\n",
    "* Data Processing: Hard\n",
    "* Modeling: Easy\n",
    "* Interactive: Medium\n",
    "\n",
    "[LibriSpeech](https://www.openslr.org/12/) is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read audiobooks from the LibriVox project, and has been carefully segmented and aligned. \n",
    "\n",
    "The goal of this project is to be able to recognize audio files, translate them into text, and find meaning out of the text.\n",
    "\n",
    "You are tasked to do the following:\n",
    "\n",
    "* Gather numerous different audio files with different lengths. In your presentation, make a note of your sample distribution of audio files, i.e. average/median time, historgram, etc.\n",
    "* Transcribe the audio and combine all texts in a dataframe\n",
    "* Clean any data, if necessary.\n",
    "* Extract name entities from the text. You may train a custom NER model if you prefer.\n",
    "* Provide summaries for longer audio files in three ways:\n",
    "    - Long summary (multiple paragraphs)\n",
    "    - Short summary (one paragraph)\n",
    "    - Tiny summary (one sentence)\n",
    "* Build an interactive tool that takes an audio file, extracts name entities and provides full text and summaries of the file.\n",
    "* Add any other techniques taught from the course that could be applied for this project.\n",
    "* Present these findings in a 10 minute video with slides, sample code and a demonstration of your interactive tool.\n",
    "\n",
    "To help with this assignment, I suggest using [whisper](https://github.com/openai/whisper) from OpenAI or [Wave2Vec2](https://huggingface.co/docs/transformers/en/model_doc/wav2vec2) to translate the audio into text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc5b5c",
   "metadata": {},
   "source": [
    "## Option 4: Find your Own Dataset and Train\n",
    "\n",
    "Finally, you may choose your own project and find a database that works well with the materials from the course. You **must** have the following with this option:\n",
    "\n",
    "* Intense data cleaning and processing text\n",
    "* At least two models predicting on data, one of which must be from tensorflow\n",
    "* Has an interactive tool showcasing findings\n",
    "\n",
    "**This option must be first accepted before working on it.** You must send a written proposal detailing the dataset and what you would like to do with it before completing. This must proposal must be sent before one week after receiving this project. From there, it will be either accepted, accepted with required changes, or denied. You may not create your own project without approval."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
