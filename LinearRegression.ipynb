{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_per_day_per_store=pd.read_csv(\"sales_per_day_per_store.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime and extract additional features\n",
    "sales_per_day_per_store['date'] = pd.to_datetime(sales_per_day_per_store['date'])\n",
    "sales_per_day_per_store['day'] = sales_per_day_per_store['date'].dt.day\n",
    "sales_per_day_per_store['month'] = sales_per_day_per_store['date'].dt.month\n",
    "sales_per_day_per_store['weekday'] = sales_per_day_per_store['date'].dt.weekday\n",
    "\n",
    "# Drop the 'date' column since it's no longer needed\n",
    "sales_per_day_per_store.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# One-hot encode categorical variables ('city', 'state', 'type')\n",
    "sales_per_day_per_store = pd.get_dummies(sales_per_day_per_store, columns=['city', 'state', 'type','is_holiday'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable (y) and features (X)\n",
    "X = sales_per_day_per_store.drop(columns=['sales','transactions'])\n",
    "y = sales_per_day_per_store['sales']\n",
    "\n",
    "# First, split 70% of the data into training, and 30% into validation and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Now, split the remaining 30% into 50% validation and 50% test (which equals 15% each of the total data)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have fitted a scaler on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit on training data\n",
    "X_valid_scaled = scaler.transform(X_valid)  # Transform validation data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)  # Transform test data using the same scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Re-initialize and re-train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)  # Train on scaled data\n",
    "\n",
    "# Make predictions again\n",
    "y_valid_pred = model.predict(X_valid_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the predictions\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_valid_pred = model.predict(X_valid_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Root Mean Squared Logarithmic Error (RMSLE).\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (array-like): Actual values\n",
    "    y_pred (array-like): Predicted values\n",
    "    \n",
    "    Returns:\n",
    "    float: RMSLE score\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Compute the logarithm of (1 + values)\n",
    "    log_true = np.log1p(1+y_true)\n",
    "    log_pred = np.log1p(1+y_pred)\n",
    "    \n",
    "    # Compute squared error\n",
    "    squared_error = (log_pred - log_true) ** 2\n",
    "    \n",
    "    # Compute mean and return the root mean squared logarithmic error\n",
    "    return np.sqrt(np.mean(squared_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Mean Squared Error: 2.455173073447924\n",
      "Validation R-squared: 0.5161357508648614\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE and R-squared for the validation set\n",
    "y_valid_pred = np.maximum(0, y_valid_pred)  # Clip negative values to zero\n",
    "mse_valid = rmsle(y_valid, y_valid_pred)\n",
    "r2_valid = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "print(f'Validation Mean Squared Error: {mse_valid}')\n",
    "print(f'Validation R-squared: {r2_valid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error: 2.4484117626693247\n",
      "Test R-squared: 0.515085619222155\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "# Calculate MSE and R-squared for the validation set\n",
    "y_test_pred = np.maximum(0, y_test_pred)  # Clip negative values to zero\n",
    "\n",
    "# Calculate MSE and R-squared for the test set\n",
    "mse_test = rmsle(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Mean Squared Error: {mse_test}')\n",
    "print(f'Test R-squared: {r2_test}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
